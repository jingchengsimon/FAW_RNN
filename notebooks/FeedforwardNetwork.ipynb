{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be879bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6593ea1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available CUDA devices:\n",
      "Device 0: NVIDIA RTX A5500\n"
     ]
    }
   ],
   "source": [
    "# list cuda devices\n",
    "print(\"Available CUDA devices:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"Device {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c914a503",
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_train_path = \"/G/MIMOlab/Codes/aim3_RNN/stimuli/stimulus_easy-train.npy\"\n",
    "label_train_path = \"/G/MIMOlab/Codes/aim3_RNN/stimuli/stimulus_easy-train.tsv\"\n",
    "stims_train = np.load(stim_train_path, allow_pickle=True)\n",
    "lbls_train = pd.read_csv(label_train_path, sep=\"\\t\", index_col=0)\n",
    "\n",
    "stim_val_path = \"/G/MIMOlab/Codes/aim3_RNN/stimuli/stimulus_easy-validation.npy\"\n",
    "label_val_path = \"/G/MIMOlab/Codes/aim3_RNN/stimuli/stimulus_easy-validation.tsv\"\n",
    "stims_val = np.load(stim_val_path, allow_pickle=True)\n",
    "lbls_val = pd.read_csv(label_val_path, sep=\"\\t\", index_col=0)\n",
    "\n",
    "mnist_img_train_path = \"/G/MIMOlab/Codes/aim3_RNN/stimuli/mnist_images_easy-train.npy\"\n",
    "mnist_lbls_train_path = \"/G/MIMOlab/Codes/aim3_RNN/stimuli/mnist_labels_easy-train.npy\"\n",
    "mnist_img_train = np.load(mnist_img_train_path, allow_pickle=True)\n",
    "mnist_lbls_train = np.load(mnist_lbls_train_path, allow_pickle=True)\n",
    "\n",
    "mnist_img_val_path = \"/G/MIMOlab/Codes/aim3_RNN/stimuli/mnist_images_easy-validation.npy\"\n",
    "mnist_lbls_val_path = \"/G/MIMOlab/Codes/aim3_RNN/stimuli/mnist_labels_easy-validation.npy\"\n",
    "mnist_img_val = np.load(mnist_img_val_path, allow_pickle=True)\n",
    "mnist_lbls_val = np.load(mnist_lbls_val_path, allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab3c704",
   "metadata": {},
   "source": [
    "## Pretrain convolution filters on MNIST characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "533c1144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset for MNIST characters\n",
    "class MNIST_Dataset(Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx][np.newaxis,:,:]\n",
    "        label = self.labels[idx]\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "204e94c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "mnist_train_ds = MNIST_Dataset(mnist_img_train, mnist_lbls_train)\n",
    "mnist_val_ds = MNIST_Dataset(mnist_img_val, mnist_lbls_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0979a8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_Classifier(nn.Module):\n",
    "    def __init__(self, device='cuda'):\n",
    "        super(MNIST_Classifier, self).__init__()\n",
    "        self.device = device\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bnorm1 = nn.BatchNorm2d(32)\n",
    "        self.bnorm2 = nn.BatchNorm2d(64)\n",
    "        self.mp1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.mp2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.model()\n",
    "        self.to(self.device)\n",
    "        \n",
    "    def model(self):\n",
    "        self.mdl = nn.Sequential(\n",
    "            self.conv1,\n",
    "            self.mp1,\n",
    "            self.bnorm1,\n",
    "            nn.ReLU(),\n",
    "            self.conv2,\n",
    "            self.mp2,\n",
    "            self.bnorm2,\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            self.fc1,\n",
    "            self.dropout,\n",
    "            self.fc2\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mdl(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "393c8c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 96.58%\n",
      "Validation Accuracy: 97.95%\n",
      "Validation Accuracy: 99.12%\n",
      "Validation Accuracy: 98.93%\n",
      "Validation Accuracy: 98.73%\n",
      "Validation Accuracy: 98.44%\n",
      "Validation Accuracy: 98.73%\n",
      "Validation Accuracy: 98.93%\n",
      "Validation Accuracy: 97.46%\n",
      "Validation Accuracy: 98.73%\n",
      "Validation Accuracy: 98.54%\n",
      "Validation Accuracy: 98.54%\n",
      "Validation Accuracy: 98.54%\n",
      "Validation Accuracy: 98.83%\n",
      "Validation Accuracy: 99.02%\n",
      "Validation Accuracy: 99.12%\n",
      "Validation Accuracy: 98.73%\n",
      "Validation Accuracy: 98.44%\n",
      "Validation Accuracy: 98.73%\n",
      "Validation Accuracy: 98.54%\n",
      "Validation Accuracy: 98.63%\n",
      "Validation Accuracy: 98.93%\n",
      "Validation Accuracy: 98.73%\n",
      "Validation Accuracy: 98.54%\n",
      "Validation Accuracy: 98.34%\n",
      "Validation Accuracy: 99.02%\n",
      "Validation Accuracy: 98.14%\n",
      "Validation Accuracy: 98.93%\n",
      "Validation Accuracy: 99.41%\n",
      "Validation Accuracy: 99.32%\n",
      "Validation Accuracy: 99.22%\n",
      "Validation Accuracy: 98.63%\n",
      "Validation Accuracy: 98.34%\n",
      "Validation Accuracy: 98.93%\n",
      "Validation Accuracy: 98.34%\n",
      "Validation Accuracy: 98.93%\n",
      "Validation Accuracy: 98.73%\n",
      "Validation Accuracy: 98.54%\n",
      "Validation Accuracy: 99.22%\n",
      "Validation Accuracy: 99.41%\n",
      "Validation Accuracy: 98.63%\n",
      "Validation Accuracy: 98.34%\n",
      "Validation Accuracy: 99.02%\n",
      "Validation Accuracy: 98.54%\n",
      "Validation Accuracy: 99.12%\n",
      "Validation Accuracy: 98.63%\n",
      "Validation Accuracy: 98.44%\n",
      "Validation Accuracy: 99.02%\n",
      "Validation Accuracy: 98.73%\n",
      "Validation Accuracy: 98.93%\n",
      "Validation Accuracy: 99.41%\n",
      "Validation Accuracy: 98.24%\n",
      "Validation Accuracy: 98.83%\n",
      "Validation Accuracy: 98.73%\n",
      "Validation Accuracy: 98.24%\n",
      "Validation Accuracy: 98.93%\n",
      "Validation Accuracy: 99.12%\n",
      "Validation Accuracy: 99.41%\n",
      "Validation Accuracy: 98.83%\n",
      "Validation Accuracy: 99.51%\n",
      "Validation Accuracy: 98.83%\n",
      "Validation Accuracy: 98.63%\n",
      "Validation Accuracy: 98.93%\n",
      "Validation Accuracy: 98.63%\n",
      "Validation Accuracy: 98.73%\n",
      "Validation Accuracy: 98.54%\n",
      "Validation Accuracy: 99.12%\n",
      "Validation Accuracy: 98.73%\n",
      "Validation Accuracy: 98.24%\n",
      "Validation Accuracy: 98.83%\n",
      "Validation Accuracy: 99.32%\n",
      "Validation Accuracy: 98.05%\n",
      "Validation Accuracy: 99.12%\n",
      "Validation Accuracy: 98.73%\n",
      "Validation Accuracy: 99.32%\n",
      "Validation Accuracy: 98.54%\n",
      "Validation Accuracy: 98.93%\n",
      "Validation Accuracy: 99.02%\n",
      "Validation Accuracy: 99.41%\n",
      "Validation Accuracy: 98.93%\n",
      "Validation Accuracy: 99.02%\n",
      "Validation Accuracy: 99.22%\n",
      "Validation Accuracy: 98.54%\n",
      "Validation Accuracy: 97.95%\n",
      "Validation Accuracy: 99.02%\n",
      "Validation Accuracy: 98.73%\n",
      "Validation Accuracy: 98.73%\n",
      "Validation Accuracy: 99.02%\n",
      "Validation Accuracy: 98.44%\n",
      "Validation Accuracy: 98.93%\n",
      "Validation Accuracy: 98.93%\n",
      "Validation Accuracy: 98.93%\n",
      "Validation Accuracy: 99.02%\n",
      "Validation Accuracy: 98.73%\n",
      "Validation Accuracy: 98.93%\n",
      "Validation Accuracy: 98.63%\n",
      "Validation Accuracy: 98.93%\n",
      "Validation Accuracy: 98.73%\n",
      "Validation Accuracy: 98.54%\n",
      "Validation Accuracy: 99.22%\n"
     ]
    }
   ],
   "source": [
    "mdl = MNIST_Classifier()\n",
    "\n",
    "optim = torch.optim.Adam(mdl.parameters(), lr=0.001)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "epoch_num = 100\n",
    "\n",
    "train_dl = DataLoader(mnist_train_ds, batch_size=64, shuffle=True)\n",
    "val_dl = DataLoader(mnist_val_ds, batch_size=1024, shuffle=True)\n",
    "\n",
    "for i in range(epoch_num):\n",
    "    mdl.train()\n",
    "    for imgs, lbls in train_dl:\n",
    "        imgs, lbls = imgs.to(mdl.device).float(), lbls.to(mdl.device).long()\n",
    "        optim.zero_grad()\n",
    "        preds = mdl(imgs)\n",
    "        loss = loss_fn(preds, lbls)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    \n",
    "    mdl.eval()\n",
    "    with torch.no_grad():\n",
    "        imgs, lbls = next(iter(val_dl))\n",
    "        imgs, lbls = imgs.to(mdl.device).float(), lbls.to(mdl.device).long()\n",
    "        preds = mdl(imgs)\n",
    "        acc = (preds.argmax(dim=1) == lbls).float().mean() * 100\n",
    "        print(f\"Validation Accuracy: {acc.item():.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0888c319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset class for loading stacks of frames as multichannel images\n",
    "# for use in testing the performance of purely feedforward models\n",
    "class MC_FF_Dataset(Dataset):\n",
    "    def __init__(self, data, labels, stack_size=3):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data (np.ndarray): Array of shape (num_samples, num_frames, height, width)\n",
    "            labels (np.ndarray): Array of shape (num_samples,) with labels\n",
    "            stack_size (int): Number of frames to stack for input as multichannel image\n",
    "        \"\"\"\n",
    "\n",
    "        self.data = data\n",
    "        self.labels = labels[['fg_char_id', 'fg_char_x', 'fg_char_y']].values\n",
    "        self.stack_size = stack_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0] - self.stack_size + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Stack frames to create a multichannel image\n",
    "        stacked_frames = self.data[idx:(idx + self.stack_size)].astype(np.float32)\n",
    "        labels = self.labels[idx + self.stack_size - 1]\n",
    "        return stacked_frames, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af5c85a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = MC_FF_Dataset(stims_train, lbls_train, stack_size=3)\n",
    "val_ds = MC_FF_Dataset(stims_val, lbls_val, stack_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52e8afca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8341f2b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s,l=train_ds[ind]\n",
    "plt.imshow(s[0, :, :])\n",
    "plt.scatter(l[1], l[2], c='r')\n",
    "plt.title(f'Character ID: {l[0]}')\n",
    "ind+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "468056b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardConv(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes, num_pos, mnist_pre=None, kernel_size=3, device='cuda'):\n",
    "        super(FeedForwardConv, self).__init__()\n",
    "        self.device = device\n",
    "        self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=kernel_size, padding='same')\n",
    "        if mnist_pre is not None:\n",
    "            # set weights of self.conv1 to mnist_pre.conv1\n",
    "            self.conv1.weight.data = torch.cat([torch.zeros(mnist_pre.conv1.weight.shape).to(self.device), \n",
    "                                                  torch.zeros(mnist_pre.conv1.weight.shape).to(self.device),\n",
    "                                                  mnist_pre.conv1.weight], dim=1)\n",
    "            self.conv1.bias.data = mnist_pre.conv1.bias.data\n",
    "        self.MP1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.LNorm1 = nn.LayerNorm([32, 48, 48])\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        if mnist_pre is not None:\n",
    "            # set weights of self.conv2 to mnist_pre.conv2\n",
    "            self.conv2.weight.data = mnist_pre.conv2.weight\n",
    "            self.conv2.bias.data = mnist_pre.conv2.bias.data\n",
    "        self.MP2 = nn.MaxPool2d(kernel_size=4, stride=4)\n",
    "        self.LNorm2 = nn.LayerNorm([64, 12, 12])\n",
    "        self.fc1 = nn.Linear(64 * 12 * 12, 512)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fcchar = nn.Linear(512, num_classes)\n",
    "        self.fcpos = nn.Linear(512, num_pos)\n",
    "        self.to(self.device)\n",
    "\n",
    "    def encoder(self, x):\n",
    "        return nn.Sequential(\n",
    "            self.conv1,\n",
    "            self.MP1,\n",
    "            self.LNorm1,\n",
    "            nn.ReLU(),\n",
    "            self.conv2,\n",
    "            self.MP2,\n",
    "            self.LNorm2,\n",
    "            nn.ReLU()\n",
    "        )(x)\n",
    "\n",
    "    def middle(self, x):\n",
    "        return nn.Sequential(\n",
    "            self.fc1,\n",
    "            nn.ReLU(),\n",
    "            self.dropout\n",
    "        )(x)\n",
    "\n",
    "    def classifier(self, x):\n",
    "        return self.fcchar(x), self.fcpos(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(self.device)\n",
    "        x = self.encoder(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.middle(x)\n",
    "\n",
    "        char_out, pos_out = self.classifier(x)\n",
    "        return char_out, pos_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649572fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train feedforward network\n",
    "def network_train(mdl, train_data, val_data, num_epochs=50, loss_weights=[1, 0.01]):\n",
    "    optim = torch.optim.Adam(mdl.parameters(), lr=0.001)\n",
    "\n",
    "    # Define loss functions\n",
    "    criterion_char = nn.CrossEntropyLoss()\n",
    "    criterion_pos = nn.MSELoss()\n",
    "\n",
    "    # data loader\n",
    "    train_dl = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "    val_dl = DataLoader(val_data, batch_size=512, shuffle=True)\n",
    "    train_acc_char = np.zeros(num_epochs)\n",
    "    val_acc_char = np.zeros(num_epochs)\n",
    "    train_err_pos = np.zeros(num_epochs)\n",
    "    val_err_pos = np.zeros(num_epochs)\n",
    "    for epoch in range(num_epochs):\n",
    "        mdl.train()\n",
    "        for batch in train_dl:\n",
    "            inputs, labels = batch\n",
    "            labels = labels.to(mdl.device)\n",
    "            labels_char = labels[:, 0].long()\n",
    "            labels_pos = labels[:, 1:].float()\n",
    "\n",
    "            optim.zero_grad()\n",
    "            out_char, out_pos = mdl(inputs)\n",
    "            loss_char = criterion_char(out_char, labels_char)\n",
    "            loss_pos = criterion_pos(out_pos, labels_pos)\n",
    "            loss = loss_weights[0]*loss_char + loss_weights[1]*loss_pos\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            train_acc_char[epoch] += (torch.argmax(out_char, dim=1) == labels_char).float().sum().item()\n",
    "            train_err_pos[epoch] += F.mse_loss(out_pos, labels_pos, reduction='sum').item()\n",
    "\n",
    "        train_acc_char[epoch] /= len(train_data)\n",
    "        train_acc_char[epoch] *= 100  # Convert to percentage\n",
    "        train_err_pos[epoch] /= len(train_data)\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Train Accuracy: {train_acc_char[epoch]:.2f}%, Train Position Error: {train_err_pos[epoch]:.2f} pix^2\")\n",
    "\n",
    "        # Print accuracy on character id for validation data\n",
    "        with torch.no_grad():\n",
    "            val_in, val_lbls = next(iter(val_dl))\n",
    "            val_lbls = val_lbls.to(mdl.device)\n",
    "            val_out_char, val_out_pos = mdl(val_in)\n",
    "            val_pred_char = torch.argmax(val_out_char, dim=1).to(mdl.device)\n",
    "            val_acc_char[epoch] = (val_pred_char == val_lbls[:, 0].long()).float().mean()*100\n",
    "            val_err_pos[epoch] = F.mse_loss(val_out_pos, val_lbls[:, 1:].float(), reduction='mean')\n",
    "            print(f\"Validation: Digit accuracy - {val_acc_char[epoch]:.2f}%, Position error - {val_err_pos[epoch]:.2f} pix^2\")\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return {\n",
    "        \"train_acc_char\": train_acc_char,\n",
    "        \"val_acc_char\": val_acc_char,\n",
    "        \"train_err_pos\": train_err_pos,\n",
    "        \"val_err_pos\": val_err_pos,\n",
    "        \"model\": mdl.to(\"cpu\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63a9d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with stack size: 3\n",
      "Epoch 1/20, Train Accuracy: 33.62%, Train Position Error: 300.50 pix^2\n",
      "Validation: Digit accuracy - 51.56%, Position error - 116.05 pix^2\n",
      "Epoch 2/20, Train Accuracy: 61.75%, Train Position Error: 232.76 pix^2\n",
      "Validation: Digit accuracy - 63.28%, Position error - 119.99 pix^2\n",
      "Epoch 3/20, Train Accuracy: 71.07%, Train Position Error: 209.12 pix^2\n",
      "Validation: Digit accuracy - 57.42%, Position error - 126.04 pix^2\n",
      "Epoch 4/20, Train Accuracy: 76.00%, Train Position Error: 193.07 pix^2\n",
      "Validation: Digit accuracy - 59.96%, Position error - 120.05 pix^2\n",
      "Epoch 5/20, Train Accuracy: 79.35%, Train Position Error: 180.73 pix^2\n",
      "Validation: Digit accuracy - 59.18%, Position error - 119.62 pix^2\n",
      "Epoch 6/20, Train Accuracy: 81.60%, Train Position Error: 170.66 pix^2\n",
      "Validation: Digit accuracy - 59.38%, Position error - 135.20 pix^2\n",
      "Epoch 7/20, Train Accuracy: 83.36%, Train Position Error: 162.79 pix^2\n",
      "Validation: Digit accuracy - 60.55%, Position error - 118.44 pix^2\n",
      "Epoch 8/20, Train Accuracy: 84.81%, Train Position Error: 155.70 pix^2\n",
      "Validation: Digit accuracy - 57.23%, Position error - 126.83 pix^2\n",
      "Epoch 9/20, Train Accuracy: 85.84%, Train Position Error: 148.92 pix^2\n",
      "Validation: Digit accuracy - 61.13%, Position error - 112.00 pix^2\n",
      "Epoch 10/20, Train Accuracy: 86.87%, Train Position Error: 143.79 pix^2\n",
      "Validation: Digit accuracy - 58.20%, Position error - 109.24 pix^2\n",
      "Epoch 11/20, Train Accuracy: 87.61%, Train Position Error: 138.67 pix^2\n",
      "Validation: Digit accuracy - 59.96%, Position error - 112.67 pix^2\n",
      "Epoch 12/20, Train Accuracy: 88.23%, Train Position Error: 134.06 pix^2\n",
      "Validation: Digit accuracy - 55.47%, Position error - 115.92 pix^2\n",
      "Epoch 13/20, Train Accuracy: 88.90%, Train Position Error: 130.71 pix^2\n",
      "Validation: Digit accuracy - 59.18%, Position error - 117.66 pix^2\n",
      "Epoch 14/20, Train Accuracy: 89.40%, Train Position Error: 127.46 pix^2\n",
      "Validation: Digit accuracy - 54.49%, Position error - 117.39 pix^2\n",
      "Epoch 15/20, Train Accuracy: 89.85%, Train Position Error: 124.14 pix^2\n",
      "Validation: Digit accuracy - 55.86%, Position error - 114.49 pix^2\n",
      "Epoch 16/20, Train Accuracy: 90.13%, Train Position Error: 121.35 pix^2\n",
      "Validation: Digit accuracy - 57.62%, Position error - 129.43 pix^2\n",
      "Epoch 17/20, Train Accuracy: 90.52%, Train Position Error: 119.41 pix^2\n",
      "Validation: Digit accuracy - 58.20%, Position error - 123.96 pix^2\n",
      "Epoch 18/20, Train Accuracy: 90.87%, Train Position Error: 117.29 pix^2\n",
      "Validation: Digit accuracy - 57.81%, Position error - 117.72 pix^2\n",
      "Epoch 19/20, Train Accuracy: 91.25%, Train Position Error: 114.85 pix^2\n",
      "Validation: Digit accuracy - 54.88%, Position error - 123.75 pix^2\n",
      "Epoch 20/20, Train Accuracy: 91.43%, Train Position Error: 113.06 pix^2\n",
      "Validation: Digit accuracy - 57.62%, Position error - 110.98 pix^2\n",
      "Training with stack size: 4\n",
      "Epoch 1/20, Train Accuracy: 35.36%, Train Position Error: 239.22 pix^2\n",
      "Validation: Digit accuracy - 57.62%, Position error - 102.70 pix^2\n",
      "Epoch 2/20, Train Accuracy: 68.01%, Train Position Error: 176.60 pix^2\n",
      "Validation: Digit accuracy - 70.12%, Position error - 79.06 pix^2\n",
      "Epoch 3/20, Train Accuracy: 77.00%, Train Position Error: 153.83 pix^2\n",
      "Validation: Digit accuracy - 74.02%, Position error - 83.06 pix^2\n",
      "Epoch 4/20, Train Accuracy: 81.21%, Train Position Error: 138.95 pix^2\n",
      "Validation: Digit accuracy - 70.51%, Position error - 71.36 pix^2\n",
      "Epoch 5/20, Train Accuracy: 83.92%, Train Position Error: 127.88 pix^2\n",
      "Validation: Digit accuracy - 70.51%, Position error - 83.90 pix^2\n",
      "Epoch 6/20, Train Accuracy: 85.83%, Train Position Error: 119.37 pix^2\n",
      "Validation: Digit accuracy - 70.31%, Position error - 81.43 pix^2\n",
      "Epoch 7/20, Train Accuracy: 87.17%, Train Position Error: 111.87 pix^2\n",
      "Validation: Digit accuracy - 73.63%, Position error - 69.70 pix^2\n",
      "Epoch 8/20, Train Accuracy: 88.36%, Train Position Error: 106.47 pix^2\n",
      "Validation: Digit accuracy - 72.46%, Position error - 65.77 pix^2\n",
      "Epoch 9/20, Train Accuracy: 89.20%, Train Position Error: 101.41 pix^2\n",
      "Validation: Digit accuracy - 66.21%, Position error - 68.40 pix^2\n",
      "Epoch 10/20, Train Accuracy: 89.95%, Train Position Error: 97.11 pix^2\n",
      "Validation: Digit accuracy - 74.80%, Position error - 71.02 pix^2\n",
      "Epoch 11/20, Train Accuracy: 90.58%, Train Position Error: 93.61 pix^2\n",
      "Validation: Digit accuracy - 70.51%, Position error - 60.97 pix^2\n",
      "Epoch 12/20, Train Accuracy: 91.02%, Train Position Error: 90.85 pix^2\n",
      "Validation: Digit accuracy - 70.70%, Position error - 64.76 pix^2\n",
      "Epoch 13/20, Train Accuracy: 91.50%, Train Position Error: 88.46 pix^2\n",
      "Validation: Digit accuracy - 64.84%, Position error - 67.40 pix^2\n",
      "Epoch 14/20, Train Accuracy: 91.87%, Train Position Error: 86.49 pix^2\n",
      "Validation: Digit accuracy - 69.34%, Position error - 64.74 pix^2\n",
      "Epoch 15/20, Train Accuracy: 92.23%, Train Position Error: 84.91 pix^2\n",
      "Validation: Digit accuracy - 68.75%, Position error - 69.77 pix^2\n",
      "Epoch 16/20, Train Accuracy: 92.36%, Train Position Error: 83.31 pix^2\n",
      "Validation: Digit accuracy - 67.38%, Position error - 73.13 pix^2\n",
      "Epoch 17/20, Train Accuracy: 92.68%, Train Position Error: 81.97 pix^2\n",
      "Validation: Digit accuracy - 63.48%, Position error - 76.56 pix^2\n",
      "Epoch 18/20, Train Accuracy: 92.87%, Train Position Error: 80.95 pix^2\n",
      "Validation: Digit accuracy - 67.77%, Position error - 71.02 pix^2\n",
      "Epoch 19/20, Train Accuracy: 93.01%, Train Position Error: 79.94 pix^2\n",
      "Validation: Digit accuracy - 72.46%, Position error - 61.86 pix^2\n",
      "Epoch 20/20, Train Accuracy: 93.27%, Train Position Error: 79.06 pix^2\n",
      "Validation: Digit accuracy - 69.92%, Position error - 68.28 pix^2\n",
      "Training with stack size: 8\n",
      "Epoch 1/20, Train Accuracy: 41.55%, Train Position Error: 182.71 pix^2\n",
      "Validation: Digit accuracy - 62.70%, Position error - 91.49 pix^2\n",
      "Epoch 2/20, Train Accuracy: 74.29%, Train Position Error: 135.09 pix^2\n",
      "Validation: Digit accuracy - 71.88%, Position error - 65.01 pix^2\n",
      "Epoch 3/20, Train Accuracy: 82.21%, Train Position Error: 114.97 pix^2\n",
      "Validation: Digit accuracy - 72.85%, Position error - 67.42 pix^2\n",
      "Epoch 4/20, Train Accuracy: 85.87%, Train Position Error: 102.47 pix^2\n",
      "Validation: Digit accuracy - 73.24%, Position error - 55.14 pix^2\n",
      "Epoch 5/20, Train Accuracy: 88.13%, Train Position Error: 92.93 pix^2\n",
      "Validation: Digit accuracy - 71.48%, Position error - 51.06 pix^2\n",
      "Epoch 6/20, Train Accuracy: 89.69%, Train Position Error: 86.17 pix^2\n",
      "Validation: Digit accuracy - 75.00%, Position error - 44.77 pix^2\n",
      "Epoch 7/20, Train Accuracy: 90.97%, Train Position Error: 80.91 pix^2\n",
      "Validation: Digit accuracy - 75.39%, Position error - 52.88 pix^2\n",
      "Epoch 8/20, Train Accuracy: 91.78%, Train Position Error: 75.65 pix^2\n",
      "Validation: Digit accuracy - 72.66%, Position error - 43.03 pix^2\n",
      "Epoch 9/20, Train Accuracy: 92.33%, Train Position Error: 72.09 pix^2\n",
      "Validation: Digit accuracy - 75.78%, Position error - 40.23 pix^2\n",
      "Epoch 10/20, Train Accuracy: 92.94%, Train Position Error: 69.14 pix^2\n",
      "Validation: Digit accuracy - 75.59%, Position error - 43.34 pix^2\n",
      "Epoch 11/20, Train Accuracy: 93.32%, Train Position Error: 66.52 pix^2\n",
      "Validation: Digit accuracy - 73.63%, Position error - 43.51 pix^2\n",
      "Epoch 12/20, Train Accuracy: 93.73%, Train Position Error: 64.55 pix^2\n",
      "Validation: Digit accuracy - 77.15%, Position error - 45.85 pix^2\n",
      "Epoch 13/20, Train Accuracy: 94.07%, Train Position Error: 63.16 pix^2\n",
      "Validation: Digit accuracy - 75.39%, Position error - 43.32 pix^2\n",
      "Epoch 14/20, Train Accuracy: 94.21%, Train Position Error: 61.25 pix^2\n",
      "Validation: Digit accuracy - 71.29%, Position error - 40.41 pix^2\n",
      "Epoch 15/20, Train Accuracy: 94.42%, Train Position Error: 60.36 pix^2\n",
      "Validation: Digit accuracy - 78.52%, Position error - 36.61 pix^2\n",
      "Epoch 16/20, Train Accuracy: 94.63%, Train Position Error: 59.41 pix^2\n",
      "Validation: Digit accuracy - 77.34%, Position error - 39.33 pix^2\n",
      "Epoch 17/20, Train Accuracy: 94.81%, Train Position Error: 58.49 pix^2\n",
      "Validation: Digit accuracy - 72.46%, Position error - 37.49 pix^2\n",
      "Epoch 18/20, Train Accuracy: 95.00%, Train Position Error: 57.56 pix^2\n",
      "Validation: Digit accuracy - 78.91%, Position error - 38.80 pix^2\n",
      "Epoch 19/20, Train Accuracy: 95.17%, Train Position Error: 56.99 pix^2\n",
      "Validation: Digit accuracy - 73.05%, Position error - 44.28 pix^2\n",
      "Epoch 20/20, Train Accuracy: 95.23%, Train Position Error: 56.42 pix^2\n",
      "Validation: Digit accuracy - 77.34%, Position error - 40.73 pix^2\n",
      "Training with stack size: 16\n",
      "Epoch 1/20, Train Accuracy: 41.49%, Train Position Error: 178.24 pix^2\n",
      "Validation: Digit accuracy - 64.26%, Position error - 74.76 pix^2\n",
      "Epoch 2/20, Train Accuracy: 75.15%, Train Position Error: 129.81 pix^2\n",
      "Validation: Digit accuracy - 68.36%, Position error - 71.72 pix^2\n",
      "Epoch 3/20, Train Accuracy: 83.20%, Train Position Error: 110.47 pix^2\n",
      "Validation: Digit accuracy - 74.22%, Position error - 59.29 pix^2\n",
      "Epoch 4/20, Train Accuracy: 86.87%, Train Position Error: 98.54 pix^2\n",
      "Validation: Digit accuracy - 76.56%, Position error - 55.00 pix^2\n",
      "Epoch 5/20, Train Accuracy: 89.12%, Train Position Error: 89.95 pix^2\n",
      "Validation: Digit accuracy - 77.73%, Position error - 47.31 pix^2\n",
      "Epoch 6/20, Train Accuracy: 90.64%, Train Position Error: 82.94 pix^2\n",
      "Validation: Digit accuracy - 75.78%, Position error - 47.82 pix^2\n",
      "Epoch 7/20, Train Accuracy: 91.74%, Train Position Error: 77.13 pix^2\n",
      "Validation: Digit accuracy - 73.24%, Position error - 42.74 pix^2\n",
      "Epoch 8/20, Train Accuracy: 92.59%, Train Position Error: 72.89 pix^2\n",
      "Validation: Digit accuracy - 75.20%, Position error - 42.76 pix^2\n",
      "Epoch 9/20, Train Accuracy: 93.16%, Train Position Error: 69.35 pix^2\n",
      "Validation: Digit accuracy - 75.20%, Position error - 40.97 pix^2\n",
      "Epoch 10/20, Train Accuracy: 93.73%, Train Position Error: 66.28 pix^2\n",
      "Validation: Digit accuracy - 75.20%, Position error - 43.81 pix^2\n",
      "Epoch 11/20, Train Accuracy: 93.98%, Train Position Error: 63.57 pix^2\n",
      "Validation: Digit accuracy - 75.78%, Position error - 43.36 pix^2\n",
      "Epoch 12/20, Train Accuracy: 94.30%, Train Position Error: 61.53 pix^2\n",
      "Validation: Digit accuracy - 70.12%, Position error - 46.32 pix^2\n",
      "Epoch 13/20, Train Accuracy: 94.61%, Train Position Error: 59.77 pix^2\n",
      "Validation: Digit accuracy - 74.02%, Position error - 41.38 pix^2\n",
      "Epoch 14/20, Train Accuracy: 94.84%, Train Position Error: 58.39 pix^2\n",
      "Validation: Digit accuracy - 74.22%, Position error - 39.99 pix^2\n",
      "Epoch 15/20, Train Accuracy: 95.03%, Train Position Error: 56.96 pix^2\n",
      "Validation: Digit accuracy - 77.93%, Position error - 35.77 pix^2\n",
      "Epoch 16/20, Train Accuracy: 95.25%, Train Position Error: 55.99 pix^2\n",
      "Validation: Digit accuracy - 76.95%, Position error - 35.54 pix^2\n",
      "Epoch 17/20, Train Accuracy: 95.34%, Train Position Error: 54.99 pix^2\n",
      "Validation: Digit accuracy - 74.80%, Position error - 46.08 pix^2\n",
      "Epoch 18/20, Train Accuracy: 95.44%, Train Position Error: 54.30 pix^2\n",
      "Validation: Digit accuracy - 74.41%, Position error - 43.99 pix^2\n",
      "Epoch 19/20, Train Accuracy: 95.62%, Train Position Error: 53.55 pix^2\n",
      "Validation: Digit accuracy - 71.48%, Position error - 33.75 pix^2\n",
      "Epoch 20/20, Train Accuracy: 95.75%, Train Position Error: 52.93 pix^2\n",
      "Validation: Digit accuracy - 74.02%, Position error - 36.76 pix^2\n"
     ]
    }
   ],
   "source": [
    "stim_train_path = \"/G/MIMOlab/Codes/aim3_RNN/stimuli/stimulus_reg-train.npy\"\n",
    "label_train_path = \"/G/MIMOlab/Codes/aim3_RNN/stimuli/stimulus_reg-train.tsv\"\n",
    "stims_train = np.load(stim_train_path, allow_pickle=True)\n",
    "lbls_train = pd.read_csv(label_train_path, sep=\"\\t\", index_col=0)\n",
    "\n",
    "stim_val_path = \"/G/MIMOlab/Codes/aim3_RNN/stimuli/stimulus_reg-validation.npy\"\n",
    "label_val_path = \"/G/MIMOlab/Codes/aim3_RNN/stimuli/stimulus_reg-validation.tsv\"\n",
    "stims_val = np.load(stim_val_path, allow_pickle=True)\n",
    "lbls_val = pd.read_csv(label_val_path, sep=\"\\t\", index_col=0)\n",
    "\n",
    "\n",
    "stack_sizes = [3, 4, 8, 16]\n",
    "results_reg_ff = []\n",
    "for ss in stack_sizes:\n",
    "    print(f\"Training with stack size: {ss}\")\n",
    "    train_ds = MC_FF_Dataset(stims_train, lbls_train, stack_size=ss)\n",
    "    val_ds = MC_FF_Dataset(stims_val, lbls_val, stack_size=ss)\n",
    "    mdl_ff = FeedForwardConv(input_channels=ss, num_classes=10, num_pos=2, kernel_size=5)\n",
    "    results_reg_ff.append(network_train(mdl_ff, train_ds, val_ds, num_epochs=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874919a5",
   "metadata": {},
   "source": [
    "## One background character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec80022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with stack size: 3\n",
      "Epoch 1/20, Train Accuracy: 46.82%, Train Position Error: 201.13 pix^2\n",
      "Validation: Digit accuracy - 37.67%, Position error - 281.28 pix^2\n",
      "Epoch 2/20, Train Accuracy: 73.05%, Train Position Error: 149.63 pix^2\n",
      "Validation: Digit accuracy - 37.82%, Position error - 278.33 pix^2\n",
      "Epoch 3/20, Train Accuracy: 79.26%, Train Position Error: 130.65 pix^2\n",
      "Validation: Digit accuracy - 40.99%, Position error - 287.42 pix^2\n",
      "Epoch 4/20, Train Accuracy: 82.56%, Train Position Error: 118.70 pix^2\n",
      "Validation: Digit accuracy - 38.55%, Position error - 299.18 pix^2\n",
      "Epoch 5/20, Train Accuracy: 84.67%, Train Position Error: 110.18 pix^2\n",
      "Validation: Digit accuracy - 41.65%, Position error - 276.86 pix^2\n",
      "Epoch 6/20, Train Accuracy: 86.23%, Train Position Error: 102.69 pix^2\n",
      "Validation: Digit accuracy - 40.19%, Position error - 285.65 pix^2\n",
      "Epoch 7/20, Train Accuracy: 87.49%, Train Position Error: 96.46 pix^2\n",
      "Validation: Digit accuracy - 40.45%, Position error - 265.57 pix^2\n",
      "Epoch 8/20, Train Accuracy: 88.55%, Train Position Error: 91.36 pix^2\n",
      "Validation: Digit accuracy - 38.28%, Position error - 279.11 pix^2\n",
      "Epoch 9/20, Train Accuracy: 89.33%, Train Position Error: 87.48 pix^2\n",
      "Validation: Digit accuracy - 40.06%, Position error - 277.65 pix^2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m val_ds = MC_FF_Dataset(stims_val, lbls_val, stack_size=ss)\n\u001b[32m     18\u001b[39m mdl_ff = FeedForwardConv(input_channels=ss, num_classes=\u001b[32m10\u001b[39m, num_pos=\u001b[32m2\u001b[39m, kernel_size=\u001b[32m5\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m results_1bg_ff.append(\u001b[43mnetwork_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmdl_ff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mnetwork_train\u001b[39m\u001b[34m(mdl, train_data, val_data, num_epochs, loss_weights)\u001b[39m\n\u001b[32m     27\u001b[39m loss_pos = criterion_pos(out_pos, labels_pos)\n\u001b[32m     28\u001b[39m loss = loss_weights[\u001b[32m0\u001b[39m]*loss_char + loss_weights[\u001b[32m1\u001b[39m]*loss_pos\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m optim.step()\n\u001b[32m     31\u001b[39m train_acc_char[epoch] += (torch.argmax(out_char, dim=\u001b[32m1\u001b[39m) == labels_char).float().sum().item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dbh60\\.conda\\envs\\rnn_env\\Lib\\site-packages\\torch\\_tensor.py:592\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    589\u001b[39m     \u001b[38;5;66;03m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[32m    590\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch._tensor_str._str(\u001b[38;5;28mself\u001b[39m, tensor_contents=tensor_contents)\n\u001b[32m--> \u001b[39m\u001b[32m592\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbackward\u001b[39m(\n\u001b[32m    593\u001b[39m     \u001b[38;5;28mself\u001b[39m, gradient=\u001b[38;5;28;01mNone\u001b[39;00m, retain_graph=\u001b[38;5;28;01mNone\u001b[39;00m, create_graph=\u001b[38;5;28;01mFalse\u001b[39;00m, inputs=\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    594\u001b[39m ):\n\u001b[32m    595\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Computes the gradient of current tensor wrt graph leaves.\u001b[39;00m\n\u001b[32m    596\u001b[39m \n\u001b[32m    597\u001b[39m \u001b[33;03m    The graph is differentiated using the chain rule. If the tensor is\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    636\u001b[39m \u001b[33;03m            used to compute the :attr:`tensors`.\u001b[39;00m\n\u001b[32m    637\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    638\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "stim_train_path = \"/G/MIMOlab/Codes/aim3_RNN/stimuli/stimulus_1bg-train.npy\"\n",
    "label_train_path = \"/G/MIMOlab/Codes/aim3_RNN/stimuli/stimulus_1bg-train.tsv\"\n",
    "stims_train = np.load(stim_train_path, allow_pickle=True)\n",
    "lbls_train = pd.read_csv(label_train_path, sep=\"\\t\", index_col=0)\n",
    "\n",
    "stim_val_path = \"/G/MIMOlab/Codes/aim3_RNN/stimuli/stimulus_1bg-validation.npy\"\n",
    "label_val_path = \"/G/MIMOlab/Codes/aim3_RNN/stimuli/stimulus_1bg-validation.tsv\"\n",
    "stims_val = np.load(stim_val_path, allow_pickle=True)\n",
    "lbls_val = pd.read_csv(label_val_path, sep=\"\\t\", index_col=0)\n",
    "\n",
    "\n",
    "stack_sizes = [3, 4, 8, 16]\n",
    "results_1bg_ff = []\n",
    "for ss in stack_sizes:\n",
    "    print(f\"Training with stack size: {ss}\")\n",
    "    train_ds = MC_FF_Dataset(stims_train, lbls_train, stack_size=ss)\n",
    "    val_ds = MC_FF_Dataset(stims_val, lbls_val, stack_size=ss)\n",
    "    mdl_ff = FeedForwardConv(input_channels=ss, num_classes=10, num_pos=2, kernel_size=5)\n",
    "    results_1bg_ff.append(network_train(mdl_ff, train_ds, val_ds, num_epochs=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d28dc4",
   "metadata": {},
   "source": [
    "## Foreground and background character have same slow speed (1 pix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b78208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with stack size: 3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m val_ds = MC_FF_Dataset(stims_val, lbls_val, stack_size=ss)\n\u001b[32m     18\u001b[39m mdl_ff = FeedForwardConv(input_channels=ss, num_classes=\u001b[32m10\u001b[39m, num_pos=\u001b[32m2\u001b[39m, kernel_size=\u001b[32m5\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m results_1bg1s_ff.append(\u001b[43mnetwork_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmdl_ff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mnetwork_train\u001b[39m\u001b[34m(mdl, train_data, val_data, num_epochs, loss_weights)\u001b[39m\n\u001b[32m     29\u001b[39m     loss.backward()\n\u001b[32m     30\u001b[39m     optim.step()\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     train_acc_char[epoch] += \u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_char\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_char\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m     train_err_pos[epoch] += F.mse_loss(out_pos, labels_pos, reduction=\u001b[33m'\u001b[39m\u001b[33msum\u001b[39m\u001b[33m'\u001b[39m).item()\n\u001b[32m     34\u001b[39m train_acc_char[epoch] /= \u001b[38;5;28mlen\u001b[39m(train_data)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "stim_train_path = \"/G/MIMOlab/Codes/aim3_RNN/stimuli/stimulus_1bg1s-train.npy\"\n",
    "label_train_path = \"/G/MIMOlab/Codes/aim3_RNN/stimuli/stimulus_1bg1s-train.tsv\"\n",
    "stims_train = np.load(stim_train_path, allow_pickle=True)\n",
    "lbls_train = pd.read_csv(label_train_path, sep=\"\\t\", index_col=0)\n",
    "\n",
    "stim_val_path = \"/G/MIMOlab/Codes/aim3_RNN/stimuli/stimulus_1bg1s-validation.npy\"\n",
    "label_val_path = \"/G/MIMOlab/Codes/aim3_RNN/stimuli/stimulus_1bg1s-validation.tsv\"\n",
    "stims_val = np.load(stim_val_path, allow_pickle=True)\n",
    "lbls_val = pd.read_csv(label_val_path, sep=\"\\t\", index_col=0)\n",
    "\n",
    "\n",
    "stack_sizes = [3, 4, 8, 16]\n",
    "results_1bg1s_ff = []\n",
    "for ss in stack_sizes:\n",
    "    print(f\"Training with stack size: {ss}\")\n",
    "    train_ds = MC_FF_Dataset(stims_train, lbls_train, stack_size=ss)\n",
    "    val_ds = MC_FF_Dataset(stims_val, lbls_val, stack_size=ss)\n",
    "    mdl_ff = FeedForwardConv(input_channels=ss, num_classes=10, num_pos=2, kernel_size=5)\n",
    "    results_1bg1s_ff.append(network_train(mdl_ff, train_ds, val_ds, num_epochs=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c4e2df",
   "metadata": {},
   "source": [
    "## Foreground and background character have same slow speed (1 pix), only training on one factor at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a15d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with stack size: 3\n",
      "Epoch 1/20, Train Accuracy: 9.81%, Train Position Error: 204.46 pix^2\n",
      "Validation: Digit accuracy - 10.47%, Position error - 97.88 pix^2\n",
      "Epoch 2/20, Train Accuracy: 9.82%, Train Position Error: 165.50 pix^2\n",
      "Validation: Digit accuracy - 11.11%, Position error - 88.79 pix^2\n",
      "Epoch 3/20, Train Accuracy: 9.80%, Train Position Error: 152.97 pix^2\n",
      "Validation: Digit accuracy - 10.62%, Position error - 96.53 pix^2\n",
      "Epoch 4/20, Train Accuracy: 9.82%, Train Position Error: 144.46 pix^2\n",
      "Validation: Digit accuracy - 10.25%, Position error - 88.93 pix^2\n",
      "Epoch 5/20, Train Accuracy: 9.85%, Train Position Error: 137.08 pix^2\n",
      "Validation: Digit accuracy - 10.86%, Position error - 90.99 pix^2\n",
      "Epoch 6/20, Train Accuracy: 9.84%, Train Position Error: 131.82 pix^2\n",
      "Validation: Digit accuracy - 10.35%, Position error - 93.88 pix^2\n",
      "Epoch 7/20, Train Accuracy: 9.81%, Train Position Error: 126.58 pix^2\n",
      "Validation: Digit accuracy - 10.47%, Position error - 87.48 pix^2\n",
      "Epoch 8/20, Train Accuracy: 9.79%, Train Position Error: 121.98 pix^2\n",
      "Validation: Digit accuracy - 10.57%, Position error - 96.12 pix^2\n",
      "Epoch 9/20, Train Accuracy: 9.76%, Train Position Error: 117.41 pix^2\n",
      "Validation: Digit accuracy - 10.47%, Position error - 92.09 pix^2\n",
      "Epoch 10/20, Train Accuracy: 9.87%, Train Position Error: 113.25 pix^2\n",
      "Validation: Digit accuracy - 9.52%, Position error - 89.38 pix^2\n",
      "Epoch 11/20, Train Accuracy: 9.83%, Train Position Error: 109.82 pix^2\n",
      "Validation: Digit accuracy - 10.72%, Position error - 88.77 pix^2\n",
      "Epoch 12/20, Train Accuracy: 9.92%, Train Position Error: 106.11 pix^2\n",
      "Validation: Digit accuracy - 11.13%, Position error - 89.22 pix^2\n",
      "Epoch 13/20, Train Accuracy: 9.81%, Train Position Error: 102.67 pix^2\n",
      "Validation: Digit accuracy - 9.45%, Position error - 91.58 pix^2\n",
      "Epoch 14/20, Train Accuracy: 9.80%, Train Position Error: 99.53 pix^2\n",
      "Validation: Digit accuracy - 10.42%, Position error - 89.39 pix^2\n",
      "Epoch 15/20, Train Accuracy: 9.72%, Train Position Error: 96.61 pix^2\n",
      "Validation: Digit accuracy - 11.01%, Position error - 91.08 pix^2\n",
      "Epoch 16/20, Train Accuracy: 9.85%, Train Position Error: 94.24 pix^2\n",
      "Validation: Digit accuracy - 9.84%, Position error - 88.57 pix^2\n",
      "Epoch 17/20, Train Accuracy: 9.87%, Train Position Error: 91.62 pix^2\n",
      "Validation: Digit accuracy - 9.33%, Position error - 88.85 pix^2\n",
      "Epoch 18/20, Train Accuracy: 9.77%, Train Position Error: 89.60 pix^2\n",
      "Validation: Digit accuracy - 10.47%, Position error - 81.65 pix^2\n",
      "Epoch 19/20, Train Accuracy: 9.93%, Train Position Error: 87.25 pix^2\n",
      "Validation: Digit accuracy - 10.18%, Position error - 88.57 pix^2\n",
      "Epoch 20/20, Train Accuracy: 9.92%, Train Position Error: 85.08 pix^2\n",
      "Validation: Digit accuracy - 9.55%, Position error - 93.27 pix^2\n",
      "Training with stack size: 4\n",
      "Epoch 1/20, Train Accuracy: 10.30%, Train Position Error: 137.36 pix^2\n",
      "Validation: Digit accuracy - 10.16%, Position error - 54.39 pix^2\n",
      "Epoch 2/20, Train Accuracy: 10.29%, Train Position Error: 99.40 pix^2\n",
      "Validation: Digit accuracy - 10.45%, Position error - 53.24 pix^2\n",
      "Epoch 3/20, Train Accuracy: 10.24%, Train Position Error: 89.14 pix^2\n",
      "Validation: Digit accuracy - 10.03%, Position error - 47.31 pix^2\n",
      "Epoch 4/20, Train Accuracy: 10.18%, Train Position Error: 82.51 pix^2\n",
      "Validation: Digit accuracy - 10.64%, Position error - 46.53 pix^2\n",
      "Epoch 5/20, Train Accuracy: 10.11%, Train Position Error: 77.99 pix^2\n",
      "Validation: Digit accuracy - 10.21%, Position error - 46.29 pix^2\n",
      "Epoch 6/20, Train Accuracy: 10.14%, Train Position Error: 74.02 pix^2\n",
      "Validation: Digit accuracy - 10.67%, Position error - 40.65 pix^2\n",
      "Epoch 7/20, Train Accuracy: 10.16%, Train Position Error: 70.55 pix^2\n",
      "Validation: Digit accuracy - 9.52%, Position error - 42.34 pix^2\n",
      "Epoch 8/20, Train Accuracy: 10.26%, Train Position Error: 67.49 pix^2\n",
      "Validation: Digit accuracy - 11.16%, Position error - 40.06 pix^2\n",
      "Epoch 9/20, Train Accuracy: 10.23%, Train Position Error: 65.25 pix^2\n",
      "Validation: Digit accuracy - 9.77%, Position error - 38.50 pix^2\n",
      "Epoch 10/20, Train Accuracy: 10.27%, Train Position Error: 62.65 pix^2\n",
      "Validation: Digit accuracy - 9.81%, Position error - 41.56 pix^2\n",
      "Epoch 11/20, Train Accuracy: 10.19%, Train Position Error: 60.59 pix^2\n",
      "Validation: Digit accuracy - 9.67%, Position error - 37.70 pix^2\n",
      "Epoch 12/20, Train Accuracy: 10.20%, Train Position Error: 58.58 pix^2\n",
      "Validation: Digit accuracy - 10.45%, Position error - 35.79 pix^2\n",
      "Epoch 13/20, Train Accuracy: 10.23%, Train Position Error: 56.70 pix^2\n",
      "Validation: Digit accuracy - 9.99%, Position error - 39.58 pix^2\n",
      "Epoch 14/20, Train Accuracy: 10.30%, Train Position Error: 55.01 pix^2\n",
      "Validation: Digit accuracy - 10.03%, Position error - 36.84 pix^2\n",
      "Epoch 15/20, Train Accuracy: 10.25%, Train Position Error: 53.41 pix^2\n",
      "Validation: Digit accuracy - 11.30%, Position error - 36.75 pix^2\n",
      "Epoch 16/20, Train Accuracy: 10.18%, Train Position Error: 51.82 pix^2\n",
      "Validation: Digit accuracy - 9.99%, Position error - 36.60 pix^2\n",
      "Epoch 17/20, Train Accuracy: 10.27%, Train Position Error: 50.35 pix^2\n",
      "Validation: Digit accuracy - 10.74%, Position error - 33.52 pix^2\n",
      "Epoch 18/20, Train Accuracy: 10.30%, Train Position Error: 48.68 pix^2\n",
      "Validation: Digit accuracy - 10.64%, Position error - 36.72 pix^2\n",
      "Epoch 19/20, Train Accuracy: 10.06%, Train Position Error: 47.14 pix^2\n",
      "Validation: Digit accuracy - 10.01%, Position error - 31.91 pix^2\n",
      "Epoch 20/20, Train Accuracy: 10.29%, Train Position Error: 45.76 pix^2\n",
      "Validation: Digit accuracy - 10.21%, Position error - 34.80 pix^2\n",
      "Training with stack size: 8\n",
      "Epoch 1/20, Train Accuracy: 9.98%, Train Position Error: 88.29 pix^2\n",
      "Validation: Digit accuracy - 10.13%, Position error - 33.99 pix^2\n",
      "Epoch 2/20, Train Accuracy: 9.89%, Train Position Error: 59.28 pix^2\n",
      "Validation: Digit accuracy - 8.72%, Position error - 29.53 pix^2\n",
      "Epoch 3/20, Train Accuracy: 9.94%, Train Position Error: 51.83 pix^2\n",
      "Validation: Digit accuracy - 9.59%, Position error - 26.55 pix^2\n",
      "Epoch 4/20, Train Accuracy: 9.85%, Train Position Error: 47.25 pix^2\n",
      "Validation: Digit accuracy - 9.47%, Position error - 24.39 pix^2\n",
      "Epoch 5/20, Train Accuracy: 9.89%, Train Position Error: 43.69 pix^2\n",
      "Validation: Digit accuracy - 9.40%, Position error - 23.30 pix^2\n",
      "Epoch 6/20, Train Accuracy: 9.88%, Train Position Error: 40.93 pix^2\n",
      "Validation: Digit accuracy - 9.62%, Position error - 24.00 pix^2\n",
      "Epoch 7/20, Train Accuracy: 9.86%, Train Position Error: 38.14 pix^2\n",
      "Validation: Digit accuracy - 9.84%, Position error - 19.80 pix^2\n",
      "Epoch 8/20, Train Accuracy: 9.89%, Train Position Error: 35.95 pix^2\n",
      "Validation: Digit accuracy - 9.74%, Position error - 20.35 pix^2\n",
      "Epoch 9/20, Train Accuracy: 9.90%, Train Position Error: 33.96 pix^2\n",
      "Validation: Digit accuracy - 10.18%, Position error - 17.63 pix^2\n",
      "Epoch 10/20, Train Accuracy: 9.88%, Train Position Error: 32.22 pix^2\n",
      "Validation: Digit accuracy - 10.33%, Position error - 18.84 pix^2\n",
      "Epoch 11/20, Train Accuracy: 9.88%, Train Position Error: 30.64 pix^2\n",
      "Validation: Digit accuracy - 10.23%, Position error - 17.21 pix^2\n",
      "Epoch 12/20, Train Accuracy: 9.86%, Train Position Error: 29.43 pix^2\n",
      "Validation: Digit accuracy - 9.01%, Position error - 17.18 pix^2\n",
      "Epoch 13/20, Train Accuracy: 9.84%, Train Position Error: 28.28 pix^2\n",
      "Validation: Digit accuracy - 9.79%, Position error - 15.59 pix^2\n",
      "Epoch 14/20, Train Accuracy: 9.86%, Train Position Error: 27.25 pix^2\n",
      "Validation: Digit accuracy - 9.38%, Position error - 17.06 pix^2\n",
      "Epoch 15/20, Train Accuracy: 9.87%, Train Position Error: 26.47 pix^2\n",
      "Validation: Digit accuracy - 9.62%, Position error - 15.70 pix^2\n",
      "Epoch 16/20, Train Accuracy: 9.81%, Train Position Error: 25.38 pix^2\n",
      "Validation: Digit accuracy - 10.06%, Position error - 14.89 pix^2\n",
      "Epoch 17/20, Train Accuracy: 9.89%, Train Position Error: 24.60 pix^2\n",
      "Validation: Digit accuracy - 9.64%, Position error - 16.43 pix^2\n",
      "Epoch 18/20, Train Accuracy: 9.78%, Train Position Error: 23.64 pix^2\n",
      "Validation: Digit accuracy - 9.67%, Position error - 15.34 pix^2\n",
      "Epoch 19/20, Train Accuracy: 9.96%, Train Position Error: 22.68 pix^2\n",
      "Validation: Digit accuracy - 9.67%, Position error - 13.55 pix^2\n",
      "Epoch 20/20, Train Accuracy: 9.81%, Train Position Error: 22.03 pix^2\n",
      "Validation: Digit accuracy - 9.74%, Position error - 13.79 pix^2\n",
      "Training with stack size: 16\n",
      "Epoch 1/20, Train Accuracy: 10.15%, Train Position Error: 86.67 pix^2\n",
      "Validation: Digit accuracy - 10.40%, Position error - 34.90 pix^2\n",
      "Epoch 2/20, Train Accuracy: 10.28%, Train Position Error: 59.14 pix^2\n",
      "Validation: Digit accuracy - 10.42%, Position error - 29.36 pix^2\n",
      "Epoch 3/20, Train Accuracy: 10.27%, Train Position Error: 52.09 pix^2\n",
      "Validation: Digit accuracy - 9.89%, Position error - 26.78 pix^2\n",
      "Epoch 4/20, Train Accuracy: 10.21%, Train Position Error: 47.36 pix^2\n",
      "Validation: Digit accuracy - 10.50%, Position error - 25.18 pix^2\n",
      "Epoch 5/20, Train Accuracy: 10.27%, Train Position Error: 43.46 pix^2\n",
      "Validation: Digit accuracy - 9.86%, Position error - 23.37 pix^2\n",
      "Epoch 6/20, Train Accuracy: 10.19%, Train Position Error: 40.30 pix^2\n",
      "Validation: Digit accuracy - 10.11%, Position error - 21.90 pix^2\n",
      "Epoch 7/20, Train Accuracy: 10.21%, Train Position Error: 37.54 pix^2\n",
      "Validation: Digit accuracy - 10.72%, Position error - 21.21 pix^2\n",
      "Epoch 8/20, Train Accuracy: 10.17%, Train Position Error: 35.09 pix^2\n",
      "Validation: Digit accuracy - 10.16%, Position error - 20.44 pix^2\n",
      "Epoch 9/20, Train Accuracy: 10.22%, Train Position Error: 33.12 pix^2\n",
      "Validation: Digit accuracy - 10.77%, Position error - 19.05 pix^2\n",
      "Epoch 10/20, Train Accuracy: 10.17%, Train Position Error: 31.25 pix^2\n",
      "Validation: Digit accuracy - 9.91%, Position error - 17.48 pix^2\n",
      "Epoch 11/20, Train Accuracy: 10.25%, Train Position Error: 29.65 pix^2\n",
      "Validation: Digit accuracy - 10.33%, Position error - 16.64 pix^2\n",
      "Epoch 12/20, Train Accuracy: 10.24%, Train Position Error: 28.32 pix^2\n",
      "Validation: Digit accuracy - 10.30%, Position error - 16.22 pix^2\n",
      "Epoch 13/20, Train Accuracy: 10.21%, Train Position Error: 27.17 pix^2\n",
      "Validation: Digit accuracy - 9.86%, Position error - 16.46 pix^2\n",
      "Epoch 14/20, Train Accuracy: 10.20%, Train Position Error: 26.13 pix^2\n",
      "Validation: Digit accuracy - 10.38%, Position error - 16.71 pix^2\n",
      "Epoch 15/20, Train Accuracy: 10.34%, Train Position Error: 25.31 pix^2\n",
      "Validation: Digit accuracy - 10.77%, Position error - 16.06 pix^2\n",
      "Epoch 16/20, Train Accuracy: 10.37%, Train Position Error: 24.53 pix^2\n",
      "Validation: Digit accuracy - 9.72%, Position error - 15.87 pix^2\n",
      "Epoch 17/20, Train Accuracy: 10.29%, Train Position Error: 23.64 pix^2\n",
      "Validation: Digit accuracy - 11.13%, Position error - 15.87 pix^2\n",
      "Epoch 18/20, Train Accuracy: 10.32%, Train Position Error: 22.97 pix^2\n",
      "Validation: Digit accuracy - 10.03%, Position error - 13.25 pix^2\n",
      "Epoch 19/20, Train Accuracy: 10.32%, Train Position Error: 22.17 pix^2\n",
      "Validation: Digit accuracy - 10.50%, Position error - 13.35 pix^2\n",
      "Epoch 20/20, Train Accuracy: 10.29%, Train Position Error: 21.45 pix^2\n",
      "Validation: Digit accuracy - 10.35%, Position error - 15.76 pix^2\n"
     ]
    }
   ],
   "source": [
    "stim_train_path = \"/G/MIMOlab/Codes/aim3_RNN/stimuli/stimulus_1bg1s-train.npy\"\n",
    "label_train_path = \"/G/MIMOlab/Codes/aim3_RNN/stimuli/stimulus_1bg1s-train.tsv\"\n",
    "stims_train = np.load(stim_train_path, allow_pickle=True)\n",
    "lbls_train = pd.read_csv(label_train_path, sep=\"\\t\", index_col=0)\n",
    "\n",
    "stim_val_path = \"/G/MIMOlab/Codes/aim3_RNN/stimuli/stimulus_1bg1s-validation.npy\"\n",
    "label_val_path = \"/G/MIMOlab/Codes/aim3_RNN/stimuli/stimulus_1bg1s-validation.tsv\"\n",
    "stims_val = np.load(stim_val_path, allow_pickle=True)\n",
    "lbls_val = pd.read_csv(label_val_path, sep=\"\\t\", index_col=0)\n",
    "\n",
    "\n",
    "stack_sizes = [3, 4, 8, 16]\n",
    "results_1bg1s_ff_pos = []\n",
    "for ss in stack_sizes:\n",
    "    print(f\"Training with stack size: {ss}\")\n",
    "    train_ds = MC_FF_Dataset(stims_train, lbls_train, stack_size=ss)\n",
    "    val_ds = MC_FF_Dataset(stims_val, lbls_val, stack_size=ss)\n",
    "    mdl_ff = FeedForwardConv(input_channels=ss, num_classes=10, num_pos=2)\n",
    "    results_1bg1s_ff_pos.append(network_train(mdl_ff, train_ds, val_ds, num_epochs=20, loss_weights=[0, 0.01]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876aaae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with stack size: 3\n",
      "Epoch 1/20, Train Accuracy: 64.64%, Train Position Error: 5357.91 pix^2\n",
      "Validation: Digit accuracy - 62.65%, Position error - 2643.72 pix^2\n",
      "Epoch 2/20, Train Accuracy: 86.10%, Train Position Error: 5357.12 pix^2\n",
      "Validation: Digit accuracy - 63.23%, Position error - 2703.94 pix^2\n",
      "Epoch 3/20, Train Accuracy: 90.98%, Train Position Error: 5356.95 pix^2\n",
      "Validation: Digit accuracy - 61.69%, Position error - 2684.29 pix^2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m val_ds = MC_FF_Dataset(stims_val, lbls_val, stack_size=ss)\n\u001b[32m     18\u001b[39m mdl_ff = FeedForwardConv(input_channels=ss, num_classes=\u001b[32m10\u001b[39m, num_pos=\u001b[32m2\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m results_1bg1s_ff_char.append(\u001b[43mnetwork_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmdl_ff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mnetwork_train\u001b[39m\u001b[34m(mdl, train_data, val_data, num_epochs, loss_weights)\u001b[39m\n\u001b[32m     22\u001b[39m labels_pos = labels[:, \u001b[32m1\u001b[39m:].float()\n\u001b[32m     24\u001b[39m optim.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m out_char, out_pos = \u001b[43mmdl\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m loss_char = criterion_char(out_char, labels_char)\n\u001b[32m     27\u001b[39m loss_pos = criterion_pos(out_pos, labels_pos)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dbh60\\.conda\\envs\\rnn_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dbh60\\.conda\\envs\\rnn_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 39\u001b[39m, in \u001b[36mFeedForwardConv.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     37\u001b[39m x = x.view(x.size(\u001b[32m0\u001b[39m), -\u001b[32m1\u001b[39m)\n\u001b[32m     38\u001b[39m x = \u001b[38;5;28mself\u001b[39m.fc1(x)\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m x = \u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mReLU\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m x = \u001b[38;5;28mself\u001b[39m.dropout(x)\n\u001b[32m     41\u001b[39m char_out = \u001b[38;5;28mself\u001b[39m.fcchar(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dbh60\\.conda\\envs\\rnn_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dbh60\\.conda\\envs\\rnn_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dbh60\\.conda\\envs\\rnn_env\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:133\u001b[39m, in \u001b[36mReLU.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dbh60\\.conda\\envs\\rnn_env\\Lib\\site-packages\\torch\\nn\\functional.py:1704\u001b[39m, in \u001b[36mrelu\u001b[39m\u001b[34m(input, inplace)\u001b[39m\n\u001b[32m   1702\u001b[39m     result = torch.relu_(\u001b[38;5;28minput\u001b[39m)\n\u001b[32m   1703\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1704\u001b[39m     result = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1705\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "stim_train_path = \"/G/MIMOlab/Codes/aim3_RNN/stimuli/stimulus_1bg1s-train.npy\"\n",
    "label_train_path = \"/G/MIMOlab/Codes/aim3_RNN/stimuli/stimulus_1bg1s-train.tsv\"\n",
    "stims_train = np.load(stim_train_path, allow_pickle=True)\n",
    "lbls_train = pd.read_csv(label_train_path, sep=\"\\t\", index_col=0)\n",
    "\n",
    "stim_val_path = \"/G/MIMOlab/Codes/aim3_RNN/stimuli/stimulus_1bg1s-validation.npy\"\n",
    "label_val_path = \"/G/MIMOlab/Codes/aim3_RNN/stimuli/stimulus_1bg1s-validation.tsv\"\n",
    "stims_val = np.load(stim_val_path, allow_pickle=True)\n",
    "lbls_val = pd.read_csv(label_val_path, sep=\"\\t\", index_col=0)\n",
    "\n",
    "\n",
    "stack_sizes = [3, 4, 8, 16]\n",
    "results_1bg1s_ff_char = []\n",
    "for ss in stack_sizes:\n",
    "    print(f\"Training with stack size: {ss}\")\n",
    "    train_ds = MC_FF_Dataset(stims_train, lbls_train, stack_size=ss)\n",
    "    val_ds = MC_FF_Dataset(stims_val, lbls_val, stack_size=ss)\n",
    "    mdl_ff = FeedForwardConv(input_channels=ss, num_classes=10, num_pos=2)\n",
    "    results_1bg1s_ff_char.append(network_train(mdl_ff, train_ds, val_ds, num_epochs=20, loss_weights=[1.0, 0.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2127e9f",
   "metadata": {},
   "source": [
    "## Vary foreground and background character speeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a2f2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with stack size: 1\n",
      "Epoch 1/50, Train Accuracy: 48.61%, Train Position Error: 421.72 pix^2\n",
      "Validation: Digit accuracy - 45.56%, Position error - 222.14 pix^2\n",
      "Epoch 2/50, Train Accuracy: 69.35%, Train Position Error: 350.92 pix^2\n",
      "Validation: Digit accuracy - 47.63%, Position error - 236.55 pix^2\n",
      "Epoch 3/50, Train Accuracy: 80.67%, Train Position Error: 264.08 pix^2\n",
      "Validation: Digit accuracy - 47.00%, Position error - 264.74 pix^2\n",
      "Epoch 4/50, Train Accuracy: 87.21%, Train Position Error: 196.05 pix^2\n",
      "Validation: Digit accuracy - 48.54%, Position error - 264.82 pix^2\n",
      "Epoch 5/50, Train Accuracy: 90.86%, Train Position Error: 154.25 pix^2\n",
      "Validation: Digit accuracy - 46.53%, Position error - 274.98 pix^2\n",
      "Epoch 6/50, Train Accuracy: 93.17%, Train Position Error: 128.55 pix^2\n",
      "Validation: Digit accuracy - 47.51%, Position error - 266.84 pix^2\n",
      "Epoch 7/50, Train Accuracy: 94.51%, Train Position Error: 111.60 pix^2\n",
      "Validation: Digit accuracy - 46.00%, Position error - 272.08 pix^2\n",
      "Epoch 8/50, Train Accuracy: 95.47%, Train Position Error: 99.47 pix^2\n",
      "Validation: Digit accuracy - 46.19%, Position error - 271.31 pix^2\n",
      "Epoch 9/50, Train Accuracy: 96.12%, Train Position Error: 89.85 pix^2\n",
      "Validation: Digit accuracy - 47.14%, Position error - 265.34 pix^2\n",
      "Epoch 10/50, Train Accuracy: 96.59%, Train Position Error: 82.97 pix^2\n",
      "Validation: Digit accuracy - 45.73%, Position error - 275.61 pix^2\n",
      "Epoch 11/50, Train Accuracy: 97.05%, Train Position Error: 77.11 pix^2\n",
      "Validation: Digit accuracy - 45.75%, Position error - 271.70 pix^2\n",
      "Epoch 12/50, Train Accuracy: 97.33%, Train Position Error: 71.95 pix^2\n",
      "Validation: Digit accuracy - 47.24%, Position error - 270.40 pix^2\n",
      "Epoch 13/50, Train Accuracy: 97.55%, Train Position Error: 68.19 pix^2\n",
      "Validation: Digit accuracy - 45.85%, Position error - 253.05 pix^2\n",
      "Epoch 14/50, Train Accuracy: 97.70%, Train Position Error: 64.62 pix^2\n",
      "Validation: Digit accuracy - 46.34%, Position error - 249.84 pix^2\n",
      "Epoch 15/50, Train Accuracy: 97.90%, Train Position Error: 61.50 pix^2\n",
      "Validation: Digit accuracy - 46.24%, Position error - 270.91 pix^2\n",
      "Epoch 16/50, Train Accuracy: 98.05%, Train Position Error: 58.91 pix^2\n",
      "Validation: Digit accuracy - 45.14%, Position error - 265.75 pix^2\n",
      "Epoch 17/50, Train Accuracy: 98.12%, Train Position Error: 56.41 pix^2\n",
      "Validation: Digit accuracy - 45.95%, Position error - 253.07 pix^2\n",
      "Epoch 18/50, Train Accuracy: 98.27%, Train Position Error: 54.03 pix^2\n",
      "Validation: Digit accuracy - 45.80%, Position error - 257.65 pix^2\n",
      "Epoch 19/50, Train Accuracy: 98.38%, Train Position Error: 52.34 pix^2\n",
      "Validation: Digit accuracy - 47.24%, Position error - 251.25 pix^2\n",
      "Epoch 20/50, Train Accuracy: 98.47%, Train Position Error: 50.40 pix^2\n",
      "Validation: Digit accuracy - 45.48%, Position error - 261.34 pix^2\n",
      "Epoch 21/50, Train Accuracy: 98.51%, Train Position Error: 48.56 pix^2\n",
      "Validation: Digit accuracy - 45.12%, Position error - 251.56 pix^2\n",
      "Epoch 22/50, Train Accuracy: 98.64%, Train Position Error: 47.31 pix^2\n",
      "Validation: Digit accuracy - 46.36%, Position error - 250.34 pix^2\n",
      "Epoch 23/50, Train Accuracy: 98.67%, Train Position Error: 45.94 pix^2\n",
      "Validation: Digit accuracy - 47.07%, Position error - 249.50 pix^2\n",
      "Epoch 24/50, Train Accuracy: 98.72%, Train Position Error: 44.52 pix^2\n",
      "Validation: Digit accuracy - 46.12%, Position error - 253.48 pix^2\n",
      "Epoch 25/50, Train Accuracy: 98.77%, Train Position Error: 43.56 pix^2\n",
      "Validation: Digit accuracy - 46.04%, Position error - 254.58 pix^2\n",
      "Epoch 26/50, Train Accuracy: 98.81%, Train Position Error: 42.39 pix^2\n",
      "Validation: Digit accuracy - 46.09%, Position error - 247.80 pix^2\n",
      "Epoch 27/50, Train Accuracy: 98.85%, Train Position Error: 41.33 pix^2\n",
      "Validation: Digit accuracy - 45.87%, Position error - 242.08 pix^2\n",
      "Epoch 28/50, Train Accuracy: 98.86%, Train Position Error: 40.51 pix^2\n",
      "Validation: Digit accuracy - 48.02%, Position error - 253.15 pix^2\n",
      "Epoch 29/50, Train Accuracy: 98.92%, Train Position Error: 39.47 pix^2\n",
      "Validation: Digit accuracy - 46.34%, Position error - 244.50 pix^2\n",
      "Epoch 30/50, Train Accuracy: 98.93%, Train Position Error: 38.81 pix^2\n",
      "Validation: Digit accuracy - 45.75%, Position error - 255.49 pix^2\n",
      "Epoch 31/50, Train Accuracy: 98.98%, Train Position Error: 37.98 pix^2\n",
      "Validation: Digit accuracy - 45.68%, Position error - 244.66 pix^2\n",
      "Epoch 32/50, Train Accuracy: 99.00%, Train Position Error: 37.29 pix^2\n",
      "Validation: Digit accuracy - 46.92%, Position error - 249.07 pix^2\n",
      "Epoch 33/50, Train Accuracy: 99.02%, Train Position Error: 36.68 pix^2\n",
      "Validation: Digit accuracy - 46.51%, Position error - 252.04 pix^2\n",
      "Epoch 34/50, Train Accuracy: 99.03%, Train Position Error: 36.07 pix^2\n",
      "Validation: Digit accuracy - 43.95%, Position error - 248.68 pix^2\n",
      "Epoch 35/50, Train Accuracy: 99.04%, Train Position Error: 35.38 pix^2\n",
      "Validation: Digit accuracy - 46.24%, Position error - 253.76 pix^2\n",
      "Epoch 36/50, Train Accuracy: 99.09%, Train Position Error: 34.90 pix^2\n",
      "Validation: Digit accuracy - 46.85%, Position error - 248.53 pix^2\n",
      "Epoch 37/50, Train Accuracy: 99.10%, Train Position Error: 34.31 pix^2\n",
      "Validation: Digit accuracy - 46.39%, Position error - 251.90 pix^2\n",
      "Epoch 38/50, Train Accuracy: 99.11%, Train Position Error: 33.73 pix^2\n",
      "Validation: Digit accuracy - 45.87%, Position error - 238.69 pix^2\n",
      "Epoch 39/50, Train Accuracy: 99.13%, Train Position Error: 33.35 pix^2\n",
      "Validation: Digit accuracy - 46.92%, Position error - 251.68 pix^2\n",
      "Epoch 40/50, Train Accuracy: 99.17%, Train Position Error: 33.02 pix^2\n",
      "Validation: Digit accuracy - 46.39%, Position error - 249.39 pix^2\n",
      "Epoch 41/50, Train Accuracy: 99.16%, Train Position Error: 32.61 pix^2\n",
      "Validation: Digit accuracy - 47.27%, Position error - 242.47 pix^2\n",
      "Epoch 42/50, Train Accuracy: 99.18%, Train Position Error: 32.02 pix^2\n",
      "Validation: Digit accuracy - 46.22%, Position error - 243.92 pix^2\n",
      "Epoch 43/50, Train Accuracy: 99.17%, Train Position Error: 31.81 pix^2\n",
      "Validation: Digit accuracy - 46.95%, Position error - 246.04 pix^2\n",
      "Epoch 44/50, Train Accuracy: 99.18%, Train Position Error: 31.40 pix^2\n",
      "Validation: Digit accuracy - 46.29%, Position error - 251.78 pix^2\n",
      "Epoch 45/50, Train Accuracy: 99.16%, Train Position Error: 31.02 pix^2\n",
      "Validation: Digit accuracy - 45.39%, Position error - 253.35 pix^2\n",
      "Epoch 46/50, Train Accuracy: 99.21%, Train Position Error: 30.58 pix^2\n",
      "Validation: Digit accuracy - 45.78%, Position error - 250.12 pix^2\n",
      "Epoch 47/50, Train Accuracy: 99.21%, Train Position Error: 30.36 pix^2\n",
      "Validation: Digit accuracy - 47.19%, Position error - 245.81 pix^2\n",
      "Epoch 48/50, Train Accuracy: 99.19%, Train Position Error: 30.13 pix^2\n",
      "Validation: Digit accuracy - 47.80%, Position error - 239.52 pix^2\n",
      "Epoch 49/50, Train Accuracy: 99.22%, Train Position Error: 29.70 pix^2\n",
      "Validation: Digit accuracy - 46.39%, Position error - 245.25 pix^2\n",
      "Epoch 50/50, Train Accuracy: 99.25%, Train Position Error: 29.50 pix^2\n",
      "Validation: Digit accuracy - 46.22%, Position error - 251.25 pix^2\n",
      "Training with stack size: 2\n",
      "Epoch 1/50, Train Accuracy: 49.91%, Train Position Error: 272.53 pix^2\n",
      "Validation: Digit accuracy - 33.40%, Position error - 340.91 pix^2\n",
      "Epoch 2/50, Train Accuracy: 73.51%, Train Position Error: 205.13 pix^2\n",
      "Validation: Digit accuracy - 34.81%, Position error - 350.82 pix^2\n",
      "Epoch 3/50, Train Accuracy: 82.59%, Train Position Error: 175.59 pix^2\n",
      "Validation: Digit accuracy - 36.11%, Position error - 350.36 pix^2\n",
      "Epoch 4/50, Train Accuracy: 88.29%, Train Position Error: 150.62 pix^2\n",
      "Validation: Digit accuracy - 33.47%, Position error - 349.60 pix^2\n",
      "Epoch 5/50, Train Accuracy: 91.85%, Train Position Error: 127.76 pix^2\n",
      "Validation: Digit accuracy - 36.13%, Position error - 333.06 pix^2\n",
      "Epoch 6/50, Train Accuracy: 93.79%, Train Position Error: 108.18 pix^2\n",
      "Validation: Digit accuracy - 36.33%, Position error - 336.50 pix^2\n",
      "Epoch 7/50, Train Accuracy: 95.05%, Train Position Error: 93.75 pix^2\n",
      "Validation: Digit accuracy - 34.77%, Position error - 342.04 pix^2\n",
      "Epoch 8/50, Train Accuracy: 95.77%, Train Position Error: 82.68 pix^2\n",
      "Validation: Digit accuracy - 35.55%, Position error - 342.76 pix^2\n",
      "Epoch 9/50, Train Accuracy: 96.30%, Train Position Error: 74.33 pix^2\n",
      "Validation: Digit accuracy - 36.62%, Position error - 346.81 pix^2\n",
      "Epoch 10/50, Train Accuracy: 96.75%, Train Position Error: 67.89 pix^2\n",
      "Validation: Digit accuracy - 35.55%, Position error - 341.41 pix^2\n",
      "Epoch 11/50, Train Accuracy: 97.07%, Train Position Error: 62.88 pix^2\n",
      "Validation: Digit accuracy - 34.62%, Position error - 337.44 pix^2\n",
      "Epoch 12/50, Train Accuracy: 97.34%, Train Position Error: 58.41 pix^2\n",
      "Validation: Digit accuracy - 35.30%, Position error - 336.00 pix^2\n",
      "Epoch 13/50, Train Accuracy: 97.56%, Train Position Error: 54.97 pix^2\n",
      "Validation: Digit accuracy - 34.52%, Position error - 333.16 pix^2\n",
      "Epoch 14/50, Train Accuracy: 97.69%, Train Position Error: 51.99 pix^2\n",
      "Validation: Digit accuracy - 33.96%, Position error - 350.99 pix^2\n",
      "Epoch 15/50, Train Accuracy: 97.91%, Train Position Error: 49.12 pix^2\n",
      "Validation: Digit accuracy - 34.08%, Position error - 335.32 pix^2\n",
      "Epoch 16/50, Train Accuracy: 98.04%, Train Position Error: 47.03 pix^2\n",
      "Validation: Digit accuracy - 35.84%, Position error - 342.68 pix^2\n",
      "Epoch 17/50, Train Accuracy: 98.13%, Train Position Error: 45.05 pix^2\n",
      "Validation: Digit accuracy - 33.52%, Position error - 331.13 pix^2\n",
      "Epoch 18/50, Train Accuracy: 98.23%, Train Position Error: 43.22 pix^2\n",
      "Validation: Digit accuracy - 35.38%, Position error - 332.16 pix^2\n",
      "Epoch 19/50, Train Accuracy: 98.34%, Train Position Error: 41.43 pix^2\n",
      "Validation: Digit accuracy - 35.45%, Position error - 336.98 pix^2\n",
      "Epoch 20/50, Train Accuracy: 98.34%, Train Position Error: 40.00 pix^2\n",
      "Validation: Digit accuracy - 33.67%, Position error - 345.35 pix^2\n",
      "Epoch 21/50, Train Accuracy: 98.49%, Train Position Error: 38.80 pix^2\n",
      "Validation: Digit accuracy - 35.94%, Position error - 330.55 pix^2\n",
      "Epoch 22/50, Train Accuracy: 98.54%, Train Position Error: 37.53 pix^2\n",
      "Validation: Digit accuracy - 33.98%, Position error - 333.97 pix^2\n",
      "Epoch 23/50, Train Accuracy: 98.58%, Train Position Error: 36.42 pix^2\n",
      "Validation: Digit accuracy - 34.67%, Position error - 319.99 pix^2\n",
      "Epoch 24/50, Train Accuracy: 98.64%, Train Position Error: 35.35 pix^2\n",
      "Validation: Digit accuracy - 34.62%, Position error - 326.61 pix^2\n",
      "Epoch 25/50, Train Accuracy: 98.70%, Train Position Error: 34.46 pix^2\n",
      "Validation: Digit accuracy - 35.62%, Position error - 330.77 pix^2\n",
      "Epoch 26/50, Train Accuracy: 98.75%, Train Position Error: 33.65 pix^2\n",
      "Validation: Digit accuracy - 36.43%, Position error - 327.72 pix^2\n",
      "Epoch 27/50, Train Accuracy: 98.78%, Train Position Error: 32.83 pix^2\n",
      "Validation: Digit accuracy - 34.18%, Position error - 316.82 pix^2\n",
      "Epoch 28/50, Train Accuracy: 98.76%, Train Position Error: 32.11 pix^2\n",
      "Validation: Digit accuracy - 36.06%, Position error - 319.06 pix^2\n",
      "Epoch 29/50, Train Accuracy: 98.84%, Train Position Error: 31.41 pix^2\n",
      "Validation: Digit accuracy - 35.74%, Position error - 326.12 pix^2\n",
      "Epoch 30/50, Train Accuracy: 98.86%, Train Position Error: 30.69 pix^2\n",
      "Validation: Digit accuracy - 34.38%, Position error - 327.27 pix^2\n",
      "Epoch 31/50, Train Accuracy: 98.93%, Train Position Error: 30.13 pix^2\n",
      "Validation: Digit accuracy - 34.81%, Position error - 330.50 pix^2\n",
      "Epoch 32/50, Train Accuracy: 98.89%, Train Position Error: 29.76 pix^2\n",
      "Validation: Digit accuracy - 34.84%, Position error - 328.42 pix^2\n",
      "Epoch 33/50, Train Accuracy: 98.92%, Train Position Error: 29.03 pix^2\n",
      "Validation: Digit accuracy - 37.33%, Position error - 335.93 pix^2\n",
      "Epoch 34/50, Train Accuracy: 98.94%, Train Position Error: 28.58 pix^2\n",
      "Validation: Digit accuracy - 35.82%, Position error - 328.48 pix^2\n",
      "Epoch 35/50, Train Accuracy: 99.02%, Train Position Error: 28.06 pix^2\n",
      "Validation: Digit accuracy - 35.01%, Position error - 332.67 pix^2\n",
      "Epoch 36/50, Train Accuracy: 99.02%, Train Position Error: 27.76 pix^2\n",
      "Validation: Digit accuracy - 35.67%, Position error - 322.94 pix^2\n",
      "Epoch 37/50, Train Accuracy: 98.99%, Train Position Error: 27.25 pix^2\n",
      "Validation: Digit accuracy - 36.25%, Position error - 328.60 pix^2\n",
      "Epoch 38/50, Train Accuracy: 99.05%, Train Position Error: 26.92 pix^2\n",
      "Validation: Digit accuracy - 35.23%, Position error - 329.75 pix^2\n",
      "Epoch 39/50, Train Accuracy: 99.08%, Train Position Error: 26.51 pix^2\n",
      "Validation: Digit accuracy - 35.52%, Position error - 322.45 pix^2\n",
      "Epoch 40/50, Train Accuracy: 99.08%, Train Position Error: 26.25 pix^2\n",
      "Validation: Digit accuracy - 34.81%, Position error - 331.50 pix^2\n",
      "Epoch 41/50, Train Accuracy: 99.10%, Train Position Error: 25.81 pix^2\n",
      "Validation: Digit accuracy - 35.52%, Position error - 330.87 pix^2\n",
      "Epoch 42/50, Train Accuracy: 99.10%, Train Position Error: 25.46 pix^2\n",
      "Validation: Digit accuracy - 35.33%, Position error - 326.86 pix^2\n",
      "Epoch 43/50, Train Accuracy: 99.11%, Train Position Error: 25.38 pix^2\n",
      "Validation: Digit accuracy - 34.96%, Position error - 329.60 pix^2\n",
      "Epoch 44/50, Train Accuracy: 99.12%, Train Position Error: 24.91 pix^2\n",
      "Validation: Digit accuracy - 34.81%, Position error - 323.60 pix^2\n",
      "Epoch 45/50, Train Accuracy: 99.12%, Train Position Error: 24.77 pix^2\n",
      "Validation: Digit accuracy - 34.96%, Position error - 327.34 pix^2\n",
      "Epoch 46/50, Train Accuracy: 99.14%, Train Position Error: 24.47 pix^2\n",
      "Validation: Digit accuracy - 34.42%, Position error - 328.67 pix^2\n",
      "Epoch 47/50, Train Accuracy: 99.12%, Train Position Error: 24.16 pix^2\n",
      "Validation: Digit accuracy - 35.06%, Position error - 328.09 pix^2\n",
      "Epoch 48/50, Train Accuracy: 99.16%, Train Position Error: 23.94 pix^2\n",
      "Validation: Digit accuracy - 33.91%, Position error - 330.33 pix^2\n",
      "Epoch 49/50, Train Accuracy: 99.20%, Train Position Error: 23.74 pix^2\n",
      "Validation: Digit accuracy - 34.47%, Position error - 324.83 pix^2\n",
      "Epoch 50/50, Train Accuracy: 99.19%, Train Position Error: 23.49 pix^2\n",
      "Validation: Digit accuracy - 35.35%, Position error - 319.69 pix^2\n",
      "Training with stack size: 4\n",
      "Epoch 1/50, Train Accuracy: 62.26%, Train Position Error: 123.78 pix^2\n",
      "Validation: Digit accuracy - 49.39%, Position error - 203.38 pix^2\n",
      "Epoch 2/50, Train Accuracy: 85.85%, Train Position Error: 75.83 pix^2\n",
      "Validation: Digit accuracy - 47.63%, Position error - 205.93 pix^2\n",
      "Epoch 3/50, Train Accuracy: 91.51%, Train Position Error: 62.35 pix^2\n",
      "Validation: Digit accuracy - 45.87%, Position error - 216.03 pix^2\n",
      "Epoch 4/50, Train Accuracy: 94.41%, Train Position Error: 55.00 pix^2\n",
      "Validation: Digit accuracy - 44.14%, Position error - 217.71 pix^2\n",
      "Epoch 5/50, Train Accuracy: 95.92%, Train Position Error: 49.71 pix^2\n",
      "Validation: Digit accuracy - 44.60%, Position error - 216.55 pix^2\n",
      "Epoch 6/50, Train Accuracy: 96.87%, Train Position Error: 45.58 pix^2\n",
      "Validation: Digit accuracy - 46.56%, Position error - 206.51 pix^2\n",
      "Epoch 7/50, Train Accuracy: 97.41%, Train Position Error: 41.83 pix^2\n",
      "Validation: Digit accuracy - 45.41%, Position error - 219.43 pix^2\n",
      "Epoch 8/50, Train Accuracy: 97.75%, Train Position Error: 38.68 pix^2\n",
      "Validation: Digit accuracy - 46.78%, Position error - 196.42 pix^2\n",
      "Epoch 9/50, Train Accuracy: 98.11%, Train Position Error: 35.96 pix^2\n",
      "Validation: Digit accuracy - 42.29%, Position error - 209.20 pix^2\n",
      "Epoch 10/50, Train Accuracy: 98.32%, Train Position Error: 33.49 pix^2\n",
      "Validation: Digit accuracy - 48.29%, Position error - 194.75 pix^2\n",
      "Epoch 11/50, Train Accuracy: 98.47%, Train Position Error: 31.43 pix^2\n",
      "Validation: Digit accuracy - 46.07%, Position error - 209.46 pix^2\n",
      "Epoch 12/50, Train Accuracy: 98.60%, Train Position Error: 29.47 pix^2\n",
      "Validation: Digit accuracy - 44.31%, Position error - 205.78 pix^2\n",
      "Epoch 13/50, Train Accuracy: 98.75%, Train Position Error: 27.75 pix^2\n",
      "Validation: Digit accuracy - 47.07%, Position error - 205.02 pix^2\n",
      "Epoch 14/50, Train Accuracy: 98.79%, Train Position Error: 26.24 pix^2\n",
      "Validation: Digit accuracy - 47.17%, Position error - 197.44 pix^2\n",
      "Epoch 15/50, Train Accuracy: 98.85%, Train Position Error: 24.99 pix^2\n",
      "Validation: Digit accuracy - 45.02%, Position error - 209.72 pix^2\n",
      "Epoch 16/50, Train Accuracy: 98.92%, Train Position Error: 23.86 pix^2\n",
      "Validation: Digit accuracy - 44.17%, Position error - 191.33 pix^2\n",
      "Epoch 17/50, Train Accuracy: 98.97%, Train Position Error: 22.86 pix^2\n",
      "Validation: Digit accuracy - 46.97%, Position error - 195.42 pix^2\n",
      "Epoch 18/50, Train Accuracy: 99.03%, Train Position Error: 22.02 pix^2\n",
      "Validation: Digit accuracy - 44.48%, Position error - 198.37 pix^2\n",
      "Epoch 19/50, Train Accuracy: 99.05%, Train Position Error: 21.09 pix^2\n",
      "Validation: Digit accuracy - 45.53%, Position error - 194.99 pix^2\n",
      "Epoch 20/50, Train Accuracy: 99.12%, Train Position Error: 20.30 pix^2\n",
      "Validation: Digit accuracy - 45.19%, Position error - 191.63 pix^2\n",
      "Epoch 21/50, Train Accuracy: 99.14%, Train Position Error: 19.71 pix^2\n",
      "Validation: Digit accuracy - 45.92%, Position error - 194.38 pix^2\n",
      "Epoch 22/50, Train Accuracy: 99.16%, Train Position Error: 19.08 pix^2\n",
      "Validation: Digit accuracy - 42.68%, Position error - 198.93 pix^2\n",
      "Epoch 23/50, Train Accuracy: 99.19%, Train Position Error: 18.46 pix^2\n",
      "Validation: Digit accuracy - 45.29%, Position error - 189.27 pix^2\n",
      "Epoch 24/50, Train Accuracy: 99.23%, Train Position Error: 18.06 pix^2\n",
      "Validation: Digit accuracy - 46.41%, Position error - 195.65 pix^2\n",
      "Epoch 25/50, Train Accuracy: 99.22%, Train Position Error: 17.65 pix^2\n",
      "Validation: Digit accuracy - 43.97%, Position error - 203.76 pix^2\n",
      "Epoch 26/50, Train Accuracy: 99.27%, Train Position Error: 17.11 pix^2\n",
      "Validation: Digit accuracy - 45.02%, Position error - 205.49 pix^2\n",
      "Epoch 27/50, Train Accuracy: 99.28%, Train Position Error: 16.72 pix^2\n",
      "Validation: Digit accuracy - 37.94%, Position error - 207.19 pix^2\n",
      "Epoch 28/50, Train Accuracy: 99.28%, Train Position Error: 16.44 pix^2\n",
      "Validation: Digit accuracy - 42.90%, Position error - 196.90 pix^2\n",
      "Epoch 29/50, Train Accuracy: 99.26%, Train Position Error: 16.10 pix^2\n",
      "Validation: Digit accuracy - 41.92%, Position error - 198.63 pix^2\n",
      "Epoch 30/50, Train Accuracy: 99.32%, Train Position Error: 15.83 pix^2\n",
      "Validation: Digit accuracy - 42.38%, Position error - 198.02 pix^2\n",
      "Epoch 31/50, Train Accuracy: 99.34%, Train Position Error: 15.60 pix^2\n",
      "Validation: Digit accuracy - 42.99%, Position error - 188.30 pix^2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m val_ds = MC_FF_Dataset(stims_val, lbls_val, stack_size=ss)\n\u001b[32m     18\u001b[39m mdl_ff = FeedForwardConv(input_channels=ss, num_classes=\u001b[32m10\u001b[39m, num_pos=\u001b[32m2\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m results_easy_ff.append(\u001b[43mnetwork_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmdl_ff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mnetwork_train\u001b[39m\u001b[34m(mdl, train_data, val_data, num_epochs)\u001b[39m\n\u001b[32m     22\u001b[39m labels_pos = labels[:, \u001b[32m1\u001b[39m:].float()\n\u001b[32m     24\u001b[39m optim.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m out_char, out_pos = \u001b[43mmdl\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m loss_char = criterion_char(out_char, labels_char)\n\u001b[32m     27\u001b[39m loss_pos = criterion_pos(out_pos, labels_pos)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dbh60\\.conda\\envs\\rnn_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dbh60\\.conda\\envs\\rnn_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36mFeedForwardConv.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     36\u001b[39m x = nn.ReLU()(x)\n\u001b[32m     37\u001b[39m x = x.view(x.size(\u001b[32m0\u001b[39m), -\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m x = nn.ReLU()(x)\n\u001b[32m     40\u001b[39m x = \u001b[38;5;28mself\u001b[39m.dropout(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dbh60\\.conda\\envs\\rnn_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dbh60\\.conda\\envs\\rnn_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dbh60\\.conda\\envs\\rnn_env\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "stim_train_path = \"/G/MIMOlab/Codes/aim3_RNN/stimuli/stimulus_1bg-train.npy\"\n",
    "label_train_path = \"/G/MIMOlab/Codes/aim3_RNN/stimuli/stimulus_1bg-train.tsv\"\n",
    "stims_train = np.load(stim_train_path, allow_pickle=True)\n",
    "lbls_train = pd.read_csv(label_train_path, sep=\"\\t\", index_col=0)\n",
    "\n",
    "stim_val_path = \"/G/MIMOlab/Codes/aim3_RNN/stimuli/stimulus_1bg-validation.npy\"\n",
    "label_val_path = \"/G/MIMOlab/Codes/aim3_RNN/stimuli/stimulus_1bg-validation.tsv\"\n",
    "stims_val = np.load(stim_val_path, allow_pickle=True)\n",
    "lbls_val = pd.read_csv(label_val_path, sep=\"\\t\", index_col=0)\n",
    "\n",
    "\n",
    "stack_sizes = [1, 2, 4, 8, 16]\n",
    "results_1bg_ff = []\n",
    "for ss in stack_sizes:\n",
    "    print(f\"Training with stack size: {ss}\")\n",
    "    train_ds = MC_FF_Dataset(stims_train, lbls_train, stack_size=ss)\n",
    "    val_ds = MC_FF_Dataset(stims_val, lbls_val, stack_size=ss)\n",
    "    mdl_ff = FeedForwardConv(input_channels=ss, num_classes=10, num_pos=2)\n",
    "    results_1bg_ff.append(network_train(mdl_ff, train_ds, val_ds, num_epochs=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fffe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset class for loading stacks of frames as multichannel images\n",
    "# for use in testing the performance of RNN models\n",
    "class MC_RNN_Dataset(Dataset):\n",
    "    def __init__(self, data, labels, frame_num=3):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data (np.ndarray): Array of shape (num_samples, num_frames, height, width)\n",
    "            labels (np.ndarray): Array of shape (num_samples,) with labels\n",
    "            frame_num (int): Number of frames to stack for input as multichannel image\n",
    "        \"\"\"\n",
    "\n",
    "        self.data = data\n",
    "        self.labels = labels[['fg_char_id', 'fg_char_x', 'fg_char_y']].values\n",
    "        self.frame_num = frame_num\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0] - self.frame_num + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Stack frames to create a multichannel image\n",
    "        stacked_frames = self.data[idx:(idx + self.frame_num)].astype(np.float32)\n",
    "        # insert channel dimension\n",
    "        stacked_frames = np.expand_dims(stacked_frames, axis=1)\n",
    "        labels = self.labels[idx:(idx + self.frame_num)]\n",
    "        return stacked_frames, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca80007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset class for loading stacks of frames as multichannel images\n",
    "# for use in testing the performance of recurrent models\n",
    "class RNNConv(nn.Module):\n",
    "    def __init__(self, num_classes, num_pos, mnist_pre=None, kernel_size=3, device='cuda'):\n",
    "        super(RNNConv, self).__init__()\n",
    "        self.device = device\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=kernel_size, padding='same')\n",
    "        if mnist_pre is not None:\n",
    "            # set weights of self.conv1 to mnist_pre.conv1\n",
    "            self.conv1.weight.data = torch.cat([torch.zeros(mnist_pre.conv1.weight.shape).to(self.device), \n",
    "                                                  torch.zeros(mnist_pre.conv1.weight.shape).to(self.device),\n",
    "                                                  mnist_pre.conv1.weight], dim=1)\n",
    "            self.conv1.bias.data = mnist_pre.conv1.bias.data\n",
    "        self.MP1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.LNorm1 = nn.LayerNorm([32, 48, 48])\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        if mnist_pre is not None:\n",
    "            # set weights of self.conv2 to mnist_pre.conv2\n",
    "            self.conv2.weight.data = mnist_pre.conv2.weight\n",
    "            self.conv2.bias.data = mnist_pre.conv2.bias.data\n",
    "        self.MP2 = nn.MaxPool2d(kernel_size=4, stride=4)\n",
    "        self.LNorm2 = nn.LayerNorm([64, 12, 12])\n",
    "        self.rnn = nn.RNN(input_size=64 * 12 * 12, hidden_size=512, num_layers=1, batch_first=True)\n",
    "        self.LNormRNN = nn.LayerNorm(512)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fcchar = nn.Linear(512, num_classes)\n",
    "        self.fcpos = nn.Linear(512, num_pos)\n",
    "        self.to(self.device)\n",
    "\n",
    "    def encoder(self, x):\n",
    "        return nn.Sequential(\n",
    "            self.conv1,\n",
    "            self.MP1,\n",
    "            self.BNorm1,\n",
    "            nn.ReLU(),\n",
    "            self.conv2,\n",
    "            self.MP2,\n",
    "            self.BNorm2,\n",
    "            nn.ReLU()\n",
    "        )(x)\n",
    "\n",
    "    def middle(self, x):\n",
    "        return nn.Sequential(\n",
    "            self.rnn,\n",
    "            self.LNormRNN,\n",
    "            nn.ReLU(),\n",
    "            self.dropout\n",
    "        )(x)\n",
    "\n",
    "    def classifier(self, x):\n",
    "        return self.fcchar(x), self.fcpos(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(self.device)\n",
    "        x = self.encoder()(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.middle()(x)\n",
    "\n",
    "        char_out, pos_out = self.classifier()(x)\n",
    "        return char_out, pos_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7658a894",
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_train_path = \"/G/MIMOlab/Codes/aim3_RNN/stimuli/stimulus_reg-train.npy\"\n",
    "label_train_path = \"/G/MIMOlab/Codes/aim3_RNN/stimuli/stimulus_reg-train.tsv\"\n",
    "stims_train = np.load(stim_train_path, allow_pickle=True)\n",
    "lbls_train = pd.read_csv(label_train_path, sep=\"\\t\", index_col=0)\n",
    "\n",
    "stim_val_path = \"/G/MIMOlab/Codes/aim3_RNN/stimuli/stimulus_reg-validation.npy\"\n",
    "label_val_path = \"/G/MIMOlab/Codes/aim3_RNN/stimuli/stimulus_reg-validation.tsv\"\n",
    "stims_val = np.load(stim_val_path, allow_pickle=True)\n",
    "lbls_val = pd.read_csv(label_val_path, sep=\"\\t\", index_col=0)\n",
    "\n",
    "\n",
    "stack_sizes = [3, 4, 8, 16]\n",
    "results_reg_ff = []\n",
    "for ss in stack_sizes:\n",
    "    print(f\"Training with stack size: {ss}\")\n",
    "    train_ds = MC_RNN_Dataset(stims_train, lbls_train, stack_size=ss)\n",
    "    val_ds = MC_RNN_Dataset(stims_val, lbls_val, stack_size=ss)\n",
    "    mdl_ff = RNNConv(input_channels=ss, num_classes=10, num_pos=2, kernel_size=5)\n",
    "    results_reg_ff.append(network_train(mdl_ff, train_ds, val_ds, num_epochs=20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
